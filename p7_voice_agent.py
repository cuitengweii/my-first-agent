import streamlit as st
import asyncio
import edge_tts
from openai import OpenAI

# --- 1. é…ç½® Groq (Key å·²å¡«å¥½) ---
client = OpenAI(
    base_url="https://api.groq.com/openai/v1",
    api_key=st.secrets["GROQ_API_KEY"],
)

# --- 2. æ ¸å¿ƒå‡½æ•°ï¼šæ–‡å­—è½¬è¯­éŸ³ (TTS) ---
async def generate_audio(text, output_file="output.mp3"):
    """
    ä½¿ç”¨ Edge TTS å°†æ–‡å­—è½¬æ¢ä¸ºè¯­éŸ³æ–‡ä»¶
    Voice åˆ—è¡¨æ¨èï¼š
    - zh-CN-XiaoxiaoNeural (å¥³å£°ï¼Œæ¸©æŸ”)
    - zh-CN-YunxiNeural (ç”·å£°ï¼Œç¨³é‡)
    """
    communicate = edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural")
    await communicate.save(output_file)

def play_audio(text):
    """
    åŒ…è£…å‡½æ•°ï¼šè¿è¡Œå¼‚æ­¥ç”Ÿæˆï¼Œå¹¶åœ¨ Streamlit æ’­æ”¾
    """
    output_file = "response_audio.mp3"
    
    # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
    asyncio.run(generate_audio(text, output_file))
    
    # åœ¨ç½‘é¡µä¸Šæ˜¾ç¤ºéŸ³é¢‘æ’­æ”¾å™¨
    st.audio(output_file, format="audio/mp3", start_time=0)

# --- 3. é¡µé¢è®¾ç½® ---
st.set_page_config(page_title="è¯­éŸ³ AI", page_icon="ğŸ™ï¸")
st.title("ğŸ™ï¸ ä¼šè¯´è¯çš„ AI åŠ©æ‰‹ (Edge TTS)")
st.caption("åŸºäº Groq (Llama 3) + Edge TTS (å…è´¹è¯­éŸ³)")

# åˆå§‹åŒ–è®°å¿†
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "assistant", "content": "ä½ å¥½ï¼æˆ‘ç°åœ¨ä¸ä»…èƒ½æ‰“å­—ï¼Œè¿˜èƒ½è¯´è¯äº†ã€‚å¿«æ¥è¯•è¯•å§ï¼"}
    ]

# æ˜¾ç¤ºå†å²
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# --- 4. äº¤äº’é€»è¾‘ ---
if user_input := st.chat_input("è¾“å…¥é—®é¢˜ï¼Œæˆ‘ä¼šè¯»å‡ºç­”æ¡ˆ..."):
    # æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    with st.chat_message("user"):
        st.write(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    # AI å›ç­”
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # è°ƒç”¨ Groq
        try:
            stream = client.chat.completions.create(
                model="llama-3.1-8b-instant",
                messages=st.session_state.messages,
                stream=True,
            )
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    full_response += chunk.choices[0].delta.content
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            
            # --- å…³é”®æ­¥éª¤ï¼šè¯´å®Œè¯åï¼Œç”ŸæˆéŸ³é¢‘ ---
            # ä¸ºäº†é˜²æ­¢å¤ªé•¿çš„å­—è¯»åŠå¤©ï¼Œæˆ‘ä»¬é™åˆ¶åªè¯»å‰ 200 ä¸ªå­—ï¼Œæˆ–è€…ä½ å¯ä»¥å»æ‰è¿™ä¸ªé™åˆ¶
            if full_response:
                with st.spinner("æ­£åœ¨ç”Ÿæˆè¯­éŸ³..."):
                    play_audio(full_response)
            
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            st.error(f"å‘ç”Ÿé”™è¯¯: {e}")
